{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. 환경설정",
   "id": "f26940161af142bc"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-05T14:41:48.466456Z",
     "start_time": "2025-07-05T14:41:48.461415Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from torch.onnx.symbolic_opset11 import chunk\n",
    "from tornado.escape import json_decode\n",
    "\n",
    "load_dotenv('../.env')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. 다양한 문서 형식 처리하기\n",
    "### 2.1 PDF 문설"
   ],
   "id": "7e4a7ded80ee06d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"./data/transformer.pdf\")\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(len(pdf_docs))\n",
    "print(pdf_docs)\n",
    "print(pdf_docs[0].metadata)\n",
    "print(pdf_docs[0].page_content)\n"
   ],
   "id": "a7cb93b927f18c6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 웹 문서",
   "id": "34d3b16a934106cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "web_loader = WebBaseLoader([\"https://python.langchain.com/\", \"https://js.langchain.com/\"])\n",
    "web_docs = web_loader.load()\n",
    "print(len(web_docs))\n",
    "web_docs[0].metadata\n",
    "print(web_docs[0].page_content)"
   ],
   "id": "78c42d26f26e237f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 JSON 파일",
   "id": "ea129d66d80ca7c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:48:48.778723Z",
     "start_time": "2025-07-05T14:48:48.771732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "json_loader = JSONLoader(\n",
    "    file_path=\"./data/kakao_chat.json\",\n",
    "    jq_schema=\".messages[].content\",  # messages 배열의 content 필드만 추출\n",
    "    text_content=True  # 추출하려는 필드가 텍스트인지 여부\n",
    ")\n",
    "\n",
    "json_docs = json_loader.load()\n",
    "\n",
    "print(\"문서의 수: \", len(json_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", json_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", json_docs[0].page_content)"
   ],
   "id": "a053dc5b8b362fd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수:  5\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': '/Users/ken/IdeaProjects/vtopia/langchain_study/conda_rag/data/kakao_chat.json', 'seq_num': 1}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " 안녕하세요 여러분, 오늘 회의 시간 확인차 연락드립니다.\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:48:57.460282Z",
     "start_time": "2025-07-05T14:48:57.453751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "json_loader = JSONLoader(\n",
    "    file_path=\"./data/kakao_chat.json\",\n",
    "    jq_schema=\".messages[]\",  # messages 배열의 모든 아이템을 추출\n",
    "    text_content=False,  # 추출하려는 필드가 텍스트인지 여부\n",
    ")\n",
    "\n",
    "json_docs = json_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(json_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", json_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", json_docs[0].page_content)"
   ],
   "id": "af8680387fcfe785",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 5\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': '/Users/ken/IdeaProjects/vtopia/langchain_study/conda_rag/data/kakao_chat.json', 'seq_num': 1}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " {\"sender\": \"\\uae40\\ucca0\\uc218\", \"timestamp\": \"2023-09-15 09:30:22\", \"content\": \"\\uc548\\ub155\\ud558\\uc138\\uc694 \\uc5ec\\ub7ec\\ubd84, \\uc624\\ub298 \\ud68c\\uc758 \\uc2dc\\uac04 \\ud655\\uc778\\ucc28 \\uc5f0\\ub77d\\ub4dc\\ub9bd\\ub2c8\\ub2e4.\"}\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:49:13.300048Z",
     "start_time": "2025-07-05T14:49:13.295526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 유니코드 디코딩 (한글 문자들이 유니코드 이스케이프 시퀀스로 인코딩되어 있음)\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "decoded_json_docs = []\n",
    "for doc in json_docs:\n",
    "    decoded_data = json.loads(doc.page_content)\n",
    "\n",
    "    # 딕셔너리 형태로 저장\n",
    "    # decoded_json_docs.append({\n",
    "    #     \"metadata\": doc.metadata,\n",
    "    #     \"page_content\": json.dumps(decoded_data, ensure_ascii=False)\n",
    "    # })\n",
    "\n",
    "    # Langchain의 Document 객체\n",
    "    document_obj = Document(page_content=json.dumps(decoded_data, ensure_ascii=False), metadata=doc.metadata)\n",
    "    decoded_json_docs.append(document_obj)\n",
    "\n",
    "print(\"문서의 수:\", len(decoded_json_docs))\n",
    "print(\"-\" * 50)\n",
    "# print(\"처음 문서의 메타데이터: \\n\", decoded_json_docs[0][\"metadata\"])\n",
    "print(\"처음 문서의 메타데이터: \\n\", decoded_json_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "# print(\"처음 문서의 내용: \\n\", decoded_json_docs[0][\"page_content\"])\n",
    "print(\"처음 문서의 내용: \\n\", decoded_json_docs[0].page_content)"
   ],
   "id": "f6944755fcd1a7c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 5\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': '/Users/ken/IdeaProjects/vtopia/langchain_study/conda_rag/data/kakao_chat.json', 'seq_num': 1}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " {\"sender\": \"김철수\", \"timestamp\": \"2023-09-15 09:30:22\", \"content\": \"안녕하세요 여러분, 오늘 회의 시간 확인차 연락드립니다.\"}\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:49:29.551995Z",
     "start_time": "2025-07-05T14:49:29.545530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 메타데이터 추가하기\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"sender\"] = record.get(\"sender\")\n",
    "    metadata[\"timestamp\"] = record.get(\"timestamp\")\n",
    "    return metadata\n",
    "\n",
    "\n",
    "json_loader = JSONLoader(\n",
    "    file_path=\"./data/kakao_chat.json\",\n",
    "    jq_schema=\".messages[]\",\n",
    "    content_key=\"content\",\n",
    "    metadata_func=metadata_func,\n",
    ")\n",
    "\n",
    "json_docs = json_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(json_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", json_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", json_docs[0].page_content)"
   ],
   "id": "2e637fea80dcf077",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 5\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': '/Users/ken/IdeaProjects/vtopia/langchain_study/conda_rag/data/kakao_chat.json', 'seq_num': 1, 'sender': '김철수', 'timestamp': '2023-09-15 09:30:22'}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " 안녕하세요 여러분, 오늘 회의 시간 확인차 연락드립니다.\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:49:38.287188Z",
     "start_time": "2025-07-05T14:49:38.279945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# JSONL 파일 로드하기\n",
    "json_loader = JSONLoader(\n",
    "    file_path=\"./data/kakao_chat.jsonl\",\n",
    "    jq_schema=\".\",\n",
    "    content_key=\"content\",\n",
    "    json_lines=True,\n",
    ")\n",
    "\n",
    "json_docs = json_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(json_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", json_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", json_docs[0].page_content)"
   ],
   "id": "8b2f006b37cd7d60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 5\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': '/Users/ken/IdeaProjects/vtopia/langchain_study/conda_rag/data/kakao_chat.jsonl', 'seq_num': 1}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " 안녕하세요 여러분, 오늘 회의 시간 확인차 연락드립니다.\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T16:12:50.137312Z",
     "start_time": "2025-07-05T16:12:50.130675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 메타데이터 추가하기\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"sender\"] = record.get(\"sender\")\n",
    "    metadata[\"timestamp\"] = record.get(\"timestamp\")\n",
    "    return metadata\n",
    "\n",
    "\n",
    "json_loader = JSONLoader(\n",
    "    file_path=\"./data/kakao_chat.jsonl\",\n",
    "    jq_schema=\".\",\n",
    "    content_key=\"content\",\n",
    "    metadata_func=metadata_func,\n",
    "    json_lines=True,\n",
    ")\n",
    "\n",
    "json_docs = json_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(json_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", json_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", json_docs[0].page_content)"
   ],
   "id": "3757999c756417d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 5\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': '/Users/ken/IdeaProjects/vtopia/langchain_study/conda_rag/data/kakao_chat.jsonl', 'seq_num': 1, 'sender': '김철수', 'timestamp': '2023-09-15 09:30:22'}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " 안녕하세요 여러분, 오늘 회의 시간 확인차 연락드립니다.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.4 CSV 파일",
   "id": "673807d3af937ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T16:14:05.418724Z",
     "start_time": "2025-07-05T16:14:05.413646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "csv_loader = CSVLoader(\"./data/kbo_teams_2023.csv\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(csv_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", csv_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", csv_docs[0].page_content)"
   ],
   "id": "2301a2cb0c33003e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 10\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': './data/kbo_teams_2023.csv', 'row': 0}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " Team: KIA 타이거즈\n",
      "City: 광주\n",
      "Founded: 1982\n",
      "Home Stadium: 광주-기아 챔피언스 필드\n",
      "Championships: 11\n",
      "Introduction: KBO 리그의 전통 강호로, 역대 최다 우승 기록을 보유하고 있다. '타이거즈 스피릿'으로 유명하며, 양현종, 안치홍 등 스타 선수들을 배출했다. 광주를 연고로 하는 유일한 프로야구팀으로 지역 사랑이 강하다.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. 효과적인 텍스트 분할 전략\n",
    "### 3.1 RecursiveCharacterTextSplitter\n",
    "- RecursiveCharacterTextSplitter는 이름에서 알 수 있듯이 재귀적으로 텍스트를 분할합니다.\n",
    "- 구분자를 순차적으로 적용하여 큰 청크에서 시작하여 점진적으로 더 작은 단위로 나눕니다.\n",
    "- 일반적으로 CharacterTextSplitter보다 더 엄격하게 크기를 준수하려고 합니다."
   ],
   "id": "499f7ba8f5a08e3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T16:50:43.863634Z",
     "start_time": "2025-07-05T16:50:43.853449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # 청크 크기\n",
    "    chunk_overlap=200,  # 청크 중 중복되는 부분 크기\n",
    "    length_function=len,  # 글자 수를 기준을 분할\n",
    "    separators=[\"\\n\\n\", \"\\n\"]  # 구분자\n",
    ")\n",
    "texts = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"생성된 텍스트 청크 수: {len(texts)}\")\n",
    "print(f\"각 청크의 길이: {list(len(text.page_content) for text in texts)}\")"
   ],
   "id": "771ab9354cf41cbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 텍스트 청크 수: 52\n",
      "각 청크의 길이: [981, 910, 975, 451, 932, 998, 904, 907, 995, 385, 926, 953, 216, 920, 996, 829, 975, 910, 906, 870, 929, 961, 945, 997, 195, 977, 968, 947, 933, 965, 938, 915, 733, 952, 945, 948, 618, 980, 989, 994, 624, 945, 914, 946, 918, 988, 929, 929, 849, 812, 814, 817]\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T16:51:03.606227Z",
     "start_time": "2025-07-05T16:51:03.604078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 각 청크의 시작 부분과 끝 부분 확인\n",
    "for text in texts[:5]:\n",
    "    print(text.page_content[:200])\n",
    "    print(\"-\" * 200)\n",
    "    print(text.page_content[-200:])\n",
    "    print(\"=\" * 200)\n",
    "    print()"
   ],
   "id": "dbad3560e9c7158c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine transla\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "∗Eq\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " experimented with novel model variants, was responsible for our initial codebase, and\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "implementing tensor2tensor, replacing our earlier codebase, greatly improving results \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ormed while at Google Brain.\n",
      "‡Work performed while at Google Research.\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "1 Introduction\n",
      "Recurrent neural networks, long short-term memory [ 13] and gated recurrent [ 7] neural networks\n",
      "in particular, have been firmly established as state of the art approaches in sequence m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "========================================================================================================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4735c9a14f010f92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 정규표현식 사용",
   "id": "f06f602edacd4e01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T17:49:13.059314Z",
     "start_time": "2025-07-05T17:49:13.054687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 문장을 구분하여 분할(마침표, 느낌표, 물음표 다음에 공백이 온느 경우 문장의 끝으로 판단)\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    "    separator=r'(?<=[.!?])\\s+',\n",
    "    is_separator_regex=True,\n",
    "    keep_separator=True\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(json_docs)\n",
    "print(f\"생성된 텍스트 청크 수: {len(texts)}\")\n",
    "print(f\"각 청크의 길이: {list(len(text.page_content) for text in texts)}\")\n",
    "print()\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인\n",
    "for text in texts[:5]:\n",
    "    print(text.page_content[:50])\n",
    "    print(\"-\" * 50)\n",
    "    print(text.page_content[-50:])\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ],
   "id": "52c6f1c96212b764",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 11, which is longer than the specified 10\n",
      "Created a chunk of size 13, which is longer than the specified 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 텍스트 청크 수: 9\n",
      "각 청크의 길이: [31, 9, 15, 7, 11, 11, 27, 13, 13]\n",
      "\n",
      "안녕하세요 여러분, 오늘 회의 시간 확인차 연락드립니다.\n",
      "--------------------------------------------------\n",
      "안녕하세요 여러분, 오늘 회의 시간 확인차 연락드립니다.\n",
      "==================================================\n",
      "\n",
      "네, 안녕하세요.\n",
      "--------------------------------------------------\n",
      "네, 안녕하세요.\n",
      "==================================================\n",
      "\n",
      "오후 2시에 하기로 했어요.\n",
      "--------------------------------------------------\n",
      "오후 2시에 하기로 했어요.\n",
      "==================================================\n",
      "\n",
      "확인했습니다.\n",
      "--------------------------------------------------\n",
      "확인했습니다.\n",
      "==================================================\n",
      "\n",
      "회의실은 어디인가요?\n",
      "--------------------------------------------------\n",
      "회의실은 어디인가요?\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.3 토큰 수를 기반으로 분할\n",
    "### (1) tiktoken\n",
    "- OpenAi에서 만든 BPE Tokenizer"
   ],
   "id": "1d59091ec58d089b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T17:56:53.520621Z",
     "start_time": "2025-07-05T17:56:53.517457Z"
    }
   },
   "cell_type": "code",
   "source": "len(pdf_docs[0].page_content)",
   "id": "5fbfc3a2ac926e20",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2853"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T17:57:04.345684Z",
     "start_time": "2025-07-05T17:57:04.251650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pdf_docs[:1])\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:50])\n",
    "    print(\"-\" * 50)\n",
    "    print(chunk.page_content[-50:])\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ],
   "id": "77accf7d8fdbfd96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 3\n",
      "각 청크의 길이: [1140, 1374, 337]\n",
      "Provided proper attribution is provided, Google he\n",
      "--------------------------------------------------\n",
      "ng more parallelizable and requiring significantly\n",
      "==================================================\n",
      "\n",
      "less time to train. Our model achieves 28.4 BLEU o\n",
      "--------------------------------------------------\n",
      "countless long days designing various parts of and\n",
      "==================================================\n",
      "\n",
      "implementing tensor2tensor, replacing our earlier \n",
      "--------------------------------------------------\n",
      "h, CA, USA.arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T17:57:55.027994Z",
     "start_time": "2025-07-05T17:57:55.024159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "    # 각 청크를 토큰화\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 토큰화 결과 확인 (첫 10개 토큰만 출력)\n",
    "    print(tokens[:10])\n",
    "    # 토큰 ID를 실제 토큰(문자열)로 변환해서 출력\n",
    "    token_strings = [tokenizer.decode([token]) for token in tokens[:10]]\n",
    "    print(token_strings)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ],
   "id": "937fa2bcf4e72137",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "[36919, 291, 6300, 63124, 374, 3984, 11, 5195, 22552, 25076]\n",
      "['Provid', 'ed', ' proper', ' attribution', ' is', ' provided', ',', ' Google', ' hereby', ' grants']\n",
      "==================================================\n",
      "\n",
      "291\n",
      "[1752, 892, 311, 5542, 13, 5751, 1646, 83691, 220, 1591]\n",
      "['less', ' time', ' to', ' train', '.', ' Our', ' model', ' achieves', ' ', '28']\n",
      "==================================================\n",
      "\n",
      "83\n",
      "[95574, 287, 16000, 17, 47211, 11, 25935, 1057, 6931, 2082]\n",
      "['implement', 'ing', ' tensor', '2', 'tensor', ',', ' replacing', ' our', ' earlier', ' code']\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### (2) Hugging Face 토크나이저\n",
    "- Hugging Face tokenizer 모델이 토큰 수를 기준으로 분할"
   ],
   "id": "4c7035e0714cedcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T18:03:19.335970Z",
     "start_time": "2025-07-05T18:03:15.817222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "# 토크나이저 인코딩\n",
    "tokens = tokenizer.encode(\"안녕하세요. 반갑습니다.\")\n",
    "print(tokens)\n",
    "\n",
    "# 토큰을 출력\n",
    "print(tokenizer.convert_ids_to_tokens(tokens))\n",
    "\n",
    "# 디코딩\n",
    "print(tokenizer.decode(tokens))"
   ],
   "id": "db4005851317b372",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/langchain_study/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 107687, 5, 20451, 54272, 16367, 5, 2]\n",
      "['<s>', '▁안녕하세요', '.', '▁반', '갑', '습니다', '.', '</s>']\n",
      "<s> 안녕하세요. 반갑습니다.</s>\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T18:03:29.428238Z",
     "start_time": "2025-07-05T18:03:29.415856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pdf_docs[:1])\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "    # 각 청크를 토큰화\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 토큰화 결과 확인 (첫 10개 토큰만 출력)\n",
    "    print(tokens[:10])\n",
    "    # 토큰 ID를 실제 토큰(문자열)로 변환해서 출력\n",
    "    token_strings = tokenizer.convert_ids_to_tokens(tokens[:10])\n",
    "    print(token_strings)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ],
   "id": "5635cb8734729d55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 3\n",
      "각 청크의 길이: [749, 1094, 1008]\n",
      "\n",
      "204\n",
      "[0, 123089, 71, 27798, 99, 179236, 83, 62952, 4, 1815]\n",
      "['<s>', '▁Provide', 'd', '▁proper', '▁at', 'tribution', '▁is', '▁provided', ',', '▁Google']\n",
      "==================================================\n",
      "\n",
      "248\n",
      "[0, 51339, 214, 115774, 2843, 37067, 70, 22, 587, 820]\n",
      "['<s>', '▁perform', 'ing', '▁models', '▁also', '▁connect', '▁the', '▁en', 'co', 'der']\n",
      "==================================================\n",
      "\n",
      "232\n",
      "[0, 70, 71834, 47, 151575, 13, 903, 6528, 5, 62]\n",
      "['<s>', '▁the', '▁effort', '▁to', '▁evaluat', 'e', '▁this', '▁idea', '.', '▁A']\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.4 Semantic Chunking",
   "id": "323064ee4fa1dec4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T18:09:59.772313Z",
     "start_time": "2025-07-05T18:09:57.932730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델을 사용하여 SemanticChunker를 초기화\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OpenAIEmbeddings(),\n",
    "    breakpoint_threshold_type=\"gradient\",\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pdf_docs[:1])\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "    # 각 청크를 토큰화\n",
    "\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 내용을 확인\n",
    "    print(chunk.page_content[:100])\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ],
   "id": "4d3704f31c47709",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 2\n",
      "각 청크의 길이: [1736, 1116]\n",
      "\n",
      "422\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and\n",
      "==================================================\n",
      "\n",
      "260\n",
      "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and \n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. 문서 임베딩(Embedding) 모델\n",
    "### 4-1 OpenAi"
   ],
   "id": "cac81342654e557a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# embedding 모델\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 문서 컬렉션\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.\"\n",
    "]\n",
    "\n",
    "# 문서 임베딩\n",
    "document_embeddings = embeddings_model.embed_documents(documents)\n",
    "\n",
    "# 임베딩 결과 출력\n",
    "print(f\"임베딩 벡터의 개수: {len(document_embeddings)}\")\n",
    "print(f\"임베딩 벡터의 차원: {len(document_embeddings[0])}\")\n",
    "print(document_embeddings[0])\n",
    "\n",
    "# embed_query 사용\n",
    "embedded_query = embeddings_model.embed_query(\"인공지능이란 무엇인가요?\")\n",
    "\n",
    "# 쿼리 임베딩 결과 출력\n",
    "print(f\"쿼리 임베딩 벡터의 차원: {len(embedded_query)}\")\n",
    "print(embedded_query)"
   ],
   "id": "f4503acc11831cdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 유사도 기반 검색\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 쿼리와 가장 유사한 문서 찾기 함수\n",
    "def find_most_similar(query, doc_embeddings):\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    # similarities = [cosine_similarity(query_embedding, doc_emb) for doc_emb in doc_embeddings]\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    return documents[most_similar_index], similarities[most_similar_index]\n",
    "\n",
    "\n",
    "# 예제 쿼리\n",
    "queries = [\n",
    "    \"인공지능이란 무엇인가요?\",\n",
    "    \"딥러닝과 머신러닝의 관계는 어떻게 되나요?\",\n",
    "    \"컴퓨터가 이미지를 이해하는 방법은?\"\n",
    "]\n",
    "\n",
    "# 각 쿼리에 대해 가장 유사한 문서 찾기\n",
    "for query in queries:\n",
    "    most_similar_doc, similarity = find_most_similar(query, document_embeddings)\n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {most_similar_doc}\")\n",
    "    print(f\"유사도: {similarity:.4f}\")\n",
    "    print()"
   ],
   "id": "6f4f8a5d00b46a39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Gradio 챗봇\n",
    "### (1) invoke 실행\n",
    "- chat history 기능을 추가"
   ],
   "id": "cc19e05f42a9fa2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T18:58:41.155Z",
     "start_time": "2025-07-05T18:58:40.228943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 답변 생성 모델을 별도로 사용\n",
    "answer_llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    history_langchain_format = []\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "    history_langchain_format.append(HumanMessage(content=message))\n",
    "\n",
    "    # 현재 메시지에 대해 RAG 체인 실행\n",
    "    # rag_response = run_route_rag_chain(message)\n",
    "\n",
    "    # 답변 생성 모델에게 현재 메시지에 대한 답변 요청\n",
    "    # final_answer = answer_llm.invoke(\n",
    "    #     history_langchain_format[:-1]+[AIMessage(content=rag_response)]+[HumanMessage(content=message)]\n",
    "    # )\n",
    "    # return final_answer.content"
   ],
   "id": "bd09ed84b53a50bd",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmessages\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m HumanMessage, AIMessage\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# 답변 생성 모델을 별도로 사용\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m answer_llm = \u001B[43mChatOpenAI\u001B[49m(model=\u001B[33m\"\u001B[39m\u001B[33mgpt-4.1-nano\u001B[39m\u001B[33m\"\u001B[39m, temperature=\u001B[32m0\u001B[39m)\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34manswer_invoke\u001B[39m(message, history):\n\u001B[32m      8\u001B[39m     history_langchain_format = []\n",
      "\u001B[31mNameError\u001B[39m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7e54c8bf75e45438"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
